{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---Removal of Null Values\n",
        "\n"
      ],
      "metadata": {
        "id": "D0tPfFprYoZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = '/kaggle/input/human-stress-modified-aml1/Stress.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "print(data.head())\n",
        "null_counts = data.isnull().sum()\n",
        "print(\"Null values in each column:\\n\", null_counts)\n",
        "data_cleaned_drop = data.dropna()\n",
        "print(\"Null values after cleaning:\\n\", data.isnull().sum())"
      ],
      "metadata": {
        "id": "Z17pd-qiYREK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removal of Duplicate Row"
      ],
      "metadata": {
        "id": "qgBH2_gEYmi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = data.duplicated()\n",
        "print(\"Number of duplicate rows:\", duplicates.sum())\n",
        "duplicate_rows = data[duplicates]\n",
        "print(\"Duplicate rows:\\n\", duplicate_rows)\n",
        "data_cleaned = data.drop_duplicates()\n",
        "print(\"Number of duplicate rows after cleaning:\",\n",
        "data_cleaned.duplicated().sum())\n",
        "print(\"Cleaned dataset:\\n\", data_cleaned.head())"
      ],
      "metadata": {
        "id": "2bl6QQK6YXMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace outliers with the median of the column using Z-Score"
      ],
      "metadata": {
        "id": "voI8Li-lYkdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "z_scores = stats.zscore(data['confidence'])\n",
        "threshold = 3\n",
        "outliers_z = data[abs(z_scores) > threshold]\n",
        "print(\"Outliers in column 'confidence' using Z-score:\\n\", outliers_z)\n",
        "median_value = data['confidence'].median()\n",
        "data['confidence'] = data['confidence'].where(abs(z_scores) <= threshold,\n",
        "median_value)\n",
        "print(\"Outliers after cleaning:\\n\",\n",
        "data[abs(stats.zscore(data['confidence'])) > threshold])\n",
        "print(\"Cleaned dataset:\\n\", data.head())"
      ],
      "metadata": {
        "id": "YNY1si_tYYw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removal of 2 Attribute"
      ],
      "metadata": {
        "id": "qGkxdJWYYgSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the cols\n",
        "print(\"Columns in the dataset:\\n\", data.columns)\n",
        "columns_to_drop = ['text', 'social_timestamp']\n",
        "data_cleaned = data.drop(columns=columns_to_drop)\n",
        "print(\"Columns after dropping:\\n\", data_cleaned.columns)\n",
        "print(\"Cleaned dataset:\\n\", data_cleaned.head())"
      ],
      "metadata": {
        "id": "APdxB7HOYaUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Min-Max Feature Scaling with Standardizatio"
      ],
      "metadata": {
        "id": "nPmUHbp5YetE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "numerical_cols = ['confidence', 'label']\n",
        "min_max_scaler = MinMaxScaler()\n",
        "data_minmax_scaled = data.copy()\n",
        "data_minmax_scaled[numerical_cols] =\n",
        "min_max_scaler.fit_transform(data[numerical_cols])\n",
        "print(\"Min-Max Scaled Data:\\n\", data_minmax_scaled.head())\n",
        "standard_scaler = StandardScaler()\n",
        "data_standard_scaled = data.copy()\n",
        "data_standard_scaled[numerical_cols] =\n",
        "standard_scaler.fit_transform(data[numerical_cols])\n",
        "print(\"Standardized Data:\\n\", data_standard_scaled.head())"
      ],
      "metadata": {
        "id": "P4z2sy6PYcH2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}